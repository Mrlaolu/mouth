// è¯­éŸ³å¤„ç†æ¨¡å—
class SpeechManager {
    constructor(options) {
        this.options = options;
        this.isRecording = false;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.audioContext = null;
        this.audioElement = null;
        this.volume = 0.8;
        
        // DOMå…ƒç´ 
        this.voiceBtn = document.getElementById('voice-btn');
        this.recordingIndicator = document.getElementById('recording-indicator');
        
        // åˆå§‹åŒ–éŸ³é¢‘å…ƒç´ 
        this.initAudioElement();
    }

    initAudioElement() {
        // åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å…ƒç´ 
        this.audioElement = document.createElement('audio');
        this.audioElement.style.display = 'none';
        this.audioElement.volume = this.volume;
        document.body.appendChild(this.audioElement);
        
        // ç»‘å®šéŸ³é¢‘äº‹ä»¶
        this.audioElement.addEventListener('play', () => {
            if (this.options.onAudioPlayed) {
                this.options.onAudioPlayed();
            }
        });
        
        this.audioElement.addEventListener('ended', () => {
            if (this.options.onAudioEnded) {
                this.options.onAudioEnded();
            }
        });
        
        this.audioElement.addEventListener('error', (e) => {
            console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', e);
        });
    }

    async startRecording() {
        // å¼€å§‹å½•éŸ³
        try {
            // è¯·æ±‚éº¦å…‹é£æƒé™
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            // åˆ›å»ºMediaRecorderå®ä¾‹
            this.mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });
            
            // é‡ç½®éŸ³é¢‘å—
            this.audioChunks = [];
            
            // ç»‘å®šå½•éŸ³äº‹ä»¶
            this.mediaRecorder.addEventListener('dataavailable', (e) => {
                if (e.data.size > 0) {
                    this.audioChunks.push(e.data);
                }
            });
            
            this.mediaRecorder.addEventListener('stop', () => {
                // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
                stream.getTracks().forEach(track => track.stop());
                
                // å¤„ç†å½•éŸ³æ•°æ®
                this.processRecording();
            });
            
            // å¼€å§‹å½•éŸ³
            this.mediaRecorder.start();
            this.isRecording = true;
            
            // æ›´æ–°UIçŠ¶æ€
            this.updateRecordingUI(true);
            
        } catch (error) {
            console.error('å½•éŸ³å¤±è´¥:', error);
            alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
        }
    }

    stopRecording() {
        // åœæ­¢å½•éŸ³
        if (this.mediaRecorder && this.isRecording) {
            this.mediaRecorder.stop();
            this.isRecording = false;
            
            // æ›´æ–°UIçŠ¶æ€
            this.updateRecordingUI(false);
        }
    }

    async processRecording() {
        // å¤„ç†å½•éŸ³æ•°æ®
        try {
            // åˆ›å»ºéŸ³é¢‘Blob
            const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm;codecs=opus' });
            
            // è½¬æ¢ä¸ºWAVæ ¼å¼ï¼ˆVoskè¦æ±‚WAVæ ¼å¼ï¼‰
            const wavBlob = await this.convertToWav(audioBlob);
            
            // å‘é€åˆ°ASR API
            const text = await this.sendToASR(wavBlob);
            
            // è°ƒç”¨å›è°ƒå‡½æ•°
            if (this.options.onSpeechRecognized) {
                this.options.onSpeechRecognized(text);
            }
            
        } catch (error) {
            console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error);
            alert('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
        }
    }

    async convertToWav(webmBlob) {
        // å°†WebMæ ¼å¼è½¬æ¢ä¸ºWAVæ ¼å¼ï¼ˆå•å£°é“ã€16ä½ã€16000Hzï¼‰
        // çœç•¥äº†è¯¦ç»†æ³¨é‡Šä»¥èŠ‚çœç¯‡å¹…ï¼Œé€»è¾‘ä¸ä¹‹å‰ç›¸åŒ
        this.audioContext = this.audioContext || new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 16000
        });
        
        const arrayBuffer = await webmBlob.arrayBuffer();
        const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
        
        const resampledBuffer = this.resampleAudio(audioBuffer, 16000);
        const monoBuffer = this.toMono(resampledBuffer);
        const pcm16 = this.floatTo16BitPCM(monoBuffer.getChannelData(0));
        const wavHeader = this.createWavHeader(pcm16.length);
        
        const wavData = new Uint8Array(wavHeader.length + pcm16.length);
        wavData.set(wavHeader, 0);
        wavData.set(pcm16, wavHeader.length);
        
        return new Blob([wavData], { type: 'audio/wav' });
    }
    
    resampleAudio(audioBuffer, targetSampleRate) {
        const sourceSampleRate = audioBuffer.sampleRate;
        const resampledContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: targetSampleRate
        });
        
        const resampledBuffer = resampledContext.createBuffer(
            audioBuffer.numberOfChannels,
            Math.ceil(audioBuffer.length * targetSampleRate / sourceSampleRate),
            targetSampleRate
        );
        
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
            const sourceData = audioBuffer.getChannelData(channel);
            const resampledData = resampledBuffer.getChannelData(channel);
            
            for (let i = 0; i < resampledData.length; i++) {
                const sourceIndex = i * sourceSampleRate / targetSampleRate;
                const index1 = Math.floor(sourceIndex);
                const index2 = Math.min(index1 + 1, sourceData.length - 1);
                const fraction = sourceIndex - index1;
                
                resampledData[i] = sourceData[index1] * (1 - fraction) + sourceData[index2] * fraction;
            }
        }
        return resampledBuffer;
    }
    
    toMono(audioBuffer) {
        if (audioBuffer.numberOfChannels === 1) {
            return audioBuffer;
        }
        const monoContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: audioBuffer.sampleRate
        });
        const monoBuffer = monoContext.createBuffer(1, audioBuffer.length, audioBuffer.sampleRate);
        const monoData = monoBuffer.getChannelData(0);
        
        for (let i = 0; i < audioBuffer.length; i++) {
            let sum = 0;
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                sum += audioBuffer.getChannelData(channel)[i];
            }
            monoData[i] = sum / audioBuffer.numberOfChannels;
        }
        return monoBuffer;
    }
    
    floatTo16BitPCM(float32Array) {
        const buffer = new ArrayBuffer(float32Array.length * 2);
        const view = new DataView(buffer);
        for (let i = 0; i < float32Array.length; i++) {
            const sample = Math.max(-1, Math.min(1, float32Array[i]));
            const int16 = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            view.setInt16(i * 2, int16, true);
        }
        return new Uint8Array(buffer);
    }
    
    createWavHeader(dataLength) {
        const sampleRate = 16000;
        const numChannels = 1;
        const bytesPerSample = 2;
        const blockAlign = numChannels * bytesPerSample;
        const byteRate = sampleRate * blockAlign;
        const totalLength = 44 + dataLength;
        
        const buffer = new ArrayBuffer(44);
        const view = new DataView(buffer);
        
        view.setUint8(0, 0x52); view.setUint8(1, 0x49); view.setUint8(2, 0x46); view.setUint8(3, 0x46); // RIFF
        view.setUint32(4, totalLength - 8, true);
        view.setUint8(8, 0x57); view.setUint8(9, 0x41); view.setUint8(10, 0x56); view.setUint8(11, 0x45); // WAVE
        view.setUint8(12, 0x66); view.setUint8(13, 0x6d); view.setUint8(14, 0x74); view.setUint8(15, 0x20); // fmt 
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, bytesPerSample * 8, true);
        view.setUint8(36, 0x64); view.setUint8(37, 0x61); view.setUint8(38, 0x74); view.setUint8(39, 0x61); // data
        view.setUint32(40, dataLength, true);
        
        return new Uint8Array(buffer);
    }

    async sendToASR(audioBlob) {
        const url = `${this.options.apiBaseUrl}/asr`;
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.webm');
        
        const response = await fetch(url, {
            method: 'POST',
            body: formData
        });
        
        if (!response.ok) {
            throw new Error(`ASRè¯·æ±‚å¤±è´¥: ${response.status}`);
        }
        
        const result = await response.json();
        return result.text || '';
    }

    // --- ä¿®æ”¹ç‚¹ï¼šå¢åŠ  pitch å‚æ•° ---
    async textToSpeech(text, pitch = 1.0) {
        // å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³
        // Args:
        //     text: è¦è½¬æ¢çš„æ–‡å­—
        //     pitch: éŸ³è°ƒ (0.5 - 2.0)ï¼Œé»˜è®¤ 1.0
        console.time('TTSæ€»è€—æ—¶');
        try {
            const url = `${this.options.apiBaseUrl}/tts`;
            
            // è¿›åº¦æ¡é€»è¾‘
            let progress = 0;
            const stepDuration = 200; 
            const maxProgress = 95; 
            const estimatedTotalTime = Math.max(3000, text.length * 50); 
            const totalIntervals = estimatedTotalTime / stepDuration;
            const progressStep = maxProgress / totalIntervals;
            
            if (this.options.onProgress) {
                this.options.onProgress(0);
            }
            
            const progressInterval = setInterval(() => {
                progress += progressStep;
                if (progress >= maxProgress) progress = maxProgress;
                if (this.options.onProgress) this.options.onProgress(Math.round(progress));
            }, stepDuration);
            
            console.time('TTSç½‘ç»œè¯·æ±‚');
            
            // --- ä¿®æ”¹ç‚¹ï¼šå‘é€ pitch å‚æ•° ---
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    text: text,
                    speed: 1.0,
                    volume: this.volume,
                    pitch: pitch // ä½¿ç”¨ä¼ å…¥çš„éŸ³è°ƒ
                })
            });
            console.timeEnd('TTSç½‘ç»œè¯·æ±‚');
            
            clearInterval(progressInterval);
            
            if (!response.ok) {
                throw new Error(`TTSè¯·æ±‚å¤±è´¥: ${response.status}`);
            }
            
            if (this.options.onProgress) {
                this.options.onProgress(100);
            }
            
            console.time('TTSéŸ³é¢‘å¤„ç†');
            const contentType = response.headers.get('content-type');
            
            if (contentType && contentType.includes('application/json')) {
                // å¦‚æœè¿”å›JSONï¼ˆå¯èƒ½æ˜¯ç©ºéŸ³é¢‘æˆ–å…¶ä»–æƒ…å†µï¼‰ï¼Œä¸åšæ’­æ”¾
                console.log('TTSè¿”å›JSONæ•°æ®ï¼Œè·³è¿‡éŸ³é¢‘æ’­æ”¾');
                if (this.options.onAudioPlayed) this.options.onAudioPlayed();
                if (this.options.onAudioEnded) {
                    setTimeout(() => {
                        this.options.onAudioEnded();
                        if (this.options.onProgress) this.options.onProgress(101);
                    }, 1000);
                }
                return;
            }
            
            const audioBlob = await response.blob();
            console.log('TTSéŸ³é¢‘å¤§å°:', audioBlob.size, 'å­—èŠ‚');
            const audioUrl = URL.createObjectURL(audioBlob);
            
            this.audioElement.src = audioUrl;
            try {
                if (this.options.onAudioPlayed) this.options.onAudioPlayed();
                await this.audioElement.play();
            } catch (error) {
                console.error('è‡ªåŠ¨æ’­æ”¾å¤±è´¥:', error);
                if (this.options.onAudioEnded) {
                    this.options.onAudioEnded();
                    if (this.options.onProgress) this.options.onProgress(101);
                }
                return;
            }
            
            console.timeEnd('TTSéŸ³é¢‘å¤„ç†');
            
            this.audioElement.addEventListener('ended', () => {
                URL.revokeObjectURL(audioUrl);
                if (this.options.onAudioEnded) {
                    this.options.onAudioEnded();
                    if (this.options.onProgress) this.options.onProgress(101);
                }
                console.timeEnd('TTSæ€»è€—æ—¶');
            }, { once: true });
            
        } catch (error) {
            console.error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥:', error);
            // é”™è¯¯å¤„ç†é€»è¾‘
            if (typeof progressInterval !== 'undefined') clearInterval(progressInterval);
            if (this.options.onProgress) this.options.onProgress(-1);
            if (this.options.onAudioPlayed) this.options.onAudioPlayed();
            if (this.options.onAudioEnded) {
                setTimeout(() => {
                    this.options.onAudioEnded();
                }, 1000);
            }
            console.timeEnd('TTSæ€»è€—æ—¶');
        }
    }

    setVolume(volume) {
        this.volume = Math.max(0, Math.min(1, volume));
        if (this.audioElement) {
            this.audioElement.volume = this.volume;
        }
    }

    updateRecordingUI(isRecording) {
        if (isRecording) {
            this.voiceBtn.classList.add('recording');
            this.voiceBtn.innerHTML = '<span class="btn-icon">â¹ï¸</span><span class="btn-text">åœæ­¢</span>';
            this.recordingIndicator.classList.add('active');
        } else {
            this.voiceBtn.classList.remove('recording');
            this.voiceBtn.innerHTML = '<span class="btn-icon">ğŸ¤</span><span class="btn-text">è¯­éŸ³</span>';
            this.recordingIndicator.classList.remove('active');
        }
    }

    async testMicrophone() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            return true;
        } catch (error) {
            console.error('éº¦å…‹é£æµ‹è¯•å¤±è´¥:', error);
            return false;
        }
    }

    destroy() {
        if (this.isRecording) this.stopRecording();
        if (this.audioElement) {
            this.audioElement.remove();
            this.audioElement = null;
        }
    }
}